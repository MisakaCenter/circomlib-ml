{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model adapted from https://keras.io/examples/vision/mnist_convnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Softmax, Dense, ReLU, Dropout\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_train into one-hot format\n",
    "temp = []\n",
    "for i in range(len(y_train)):\n",
    "    temp.append(to_categorical(y_train[i], num_classes=10))\n",
    "y_train = np.array(temp)\n",
    "# Convert y_test into one-hot format\n",
    "temp = []\n",
    "for i in range(len(y_test)):    \n",
    "    temp.append(to_categorical(y_test[i], num_classes=10))\n",
    "y_test = np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype(np.float32)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(28,28,1))\n",
    "out = Conv2D(4, 3)(inputs)\n",
    "out = ReLU()(out)\n",
    "out = MaxPooling2D()(out)\n",
    "out = Conv2D(8, 3)(out)\n",
    "out = ReLU()(out)\n",
    "out = MaxPooling2D()(out)\n",
    "out = Flatten()(out)\n",
    "out = Dropout(0.5)(out)\n",
    "out = Dense(10, activation=None)(out)\n",
    "out = Softmax()(out)\n",
    "full_model = Model(inputs, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 4)         40        \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 26, 26, 4)         0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 4)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 8)         296       \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 11, 11, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 200)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                2010      \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,346\n",
      "Trainable params: 2,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['acc']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 01:15:19.413108: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 4s 7ms/step - loss: 15.1837 - acc: 0.3464 - val_loss: 1.1383 - val_acc: 0.6266\n",
      "Epoch 2/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 1.3581 - acc: 0.5707 - val_loss: 0.6394 - val_acc: 0.8276\n",
      "Epoch 3/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.9698 - acc: 0.7040 - val_loss: 0.4940 - val_acc: 0.8754\n",
      "Epoch 4/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.8298 - acc: 0.7487 - val_loss: 0.4032 - val_acc: 0.8965\n",
      "Epoch 5/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.7570 - acc: 0.7679 - val_loss: 0.3625 - val_acc: 0.9054\n",
      "Epoch 6/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.6996 - acc: 0.7855 - val_loss: 0.3243 - val_acc: 0.9122\n",
      "Epoch 7/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.6625 - acc: 0.7960 - val_loss: 0.3025 - val_acc: 0.9196\n",
      "Epoch 8/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.6175 - acc: 0.8108 - val_loss: 0.2832 - val_acc: 0.9214\n",
      "Epoch 9/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5870 - acc: 0.8208 - val_loss: 0.2648 - val_acc: 0.9255\n",
      "Epoch 10/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.5464 - acc: 0.8323 - val_loss: 0.2408 - val_acc: 0.9316\n",
      "Epoch 11/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.5161 - acc: 0.8414 - val_loss: 0.2283 - val_acc: 0.9367\n",
      "Epoch 12/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.4853 - acc: 0.8510 - val_loss: 0.2112 - val_acc: 0.9409\n",
      "Epoch 13/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.4512 - acc: 0.8611 - val_loss: 0.1907 - val_acc: 0.9462\n",
      "Epoch 14/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.4275 - acc: 0.8686 - val_loss: 0.1730 - val_acc: 0.9476\n",
      "Epoch 15/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3901 - acc: 0.8815 - val_loss: 0.1625 - val_acc: 0.9531\n",
      "Epoch 16/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3610 - acc: 0.8907 - val_loss: 0.1465 - val_acc: 0.9555\n",
      "Epoch 17/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.3334 - acc: 0.8980 - val_loss: 0.1329 - val_acc: 0.9617\n",
      "Epoch 18/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.3040 - acc: 0.9056 - val_loss: 0.1239 - val_acc: 0.9630\n",
      "Epoch 19/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2845 - acc: 0.9130 - val_loss: 0.1293 - val_acc: 0.9643\n",
      "Epoch 20/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2711 - acc: 0.9162 - val_loss: 0.1136 - val_acc: 0.9668\n",
      "Epoch 21/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2593 - acc: 0.9194 - val_loss: 0.1090 - val_acc: 0.9673\n",
      "Epoch 22/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2448 - acc: 0.9233 - val_loss: 0.1027 - val_acc: 0.9689\n",
      "Epoch 23/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2428 - acc: 0.9254 - val_loss: 0.1065 - val_acc: 0.9695\n",
      "Epoch 24/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2382 - acc: 0.9277 - val_loss: 0.0967 - val_acc: 0.9724\n",
      "Epoch 25/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2226 - acc: 0.9322 - val_loss: 0.0993 - val_acc: 0.9705\n",
      "Epoch 26/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2144 - acc: 0.9333 - val_loss: 0.0866 - val_acc: 0.9736\n",
      "Epoch 27/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2063 - acc: 0.9370 - val_loss: 0.0863 - val_acc: 0.9746\n",
      "Epoch 28/100\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2030 - acc: 0.9368 - val_loss: 0.0823 - val_acc: 0.9757\n",
      "Epoch 29/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1999 - acc: 0.9380 - val_loss: 0.0807 - val_acc: 0.9754\n",
      "Epoch 30/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1963 - acc: 0.9391 - val_loss: 0.0775 - val_acc: 0.9761\n",
      "Epoch 31/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1868 - acc: 0.9420 - val_loss: 0.0743 - val_acc: 0.9768\n",
      "Epoch 32/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1852 - acc: 0.9424 - val_loss: 0.0732 - val_acc: 0.9767\n",
      "Epoch 33/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1834 - acc: 0.9426 - val_loss: 0.0738 - val_acc: 0.9774\n",
      "Epoch 34/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1819 - acc: 0.9436 - val_loss: 0.0719 - val_acc: 0.9782\n",
      "Epoch 35/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1795 - acc: 0.9447 - val_loss: 0.0703 - val_acc: 0.9785\n",
      "Epoch 36/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1822 - acc: 0.9442 - val_loss: 0.0707 - val_acc: 0.9778\n",
      "Epoch 37/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1761 - acc: 0.9452 - val_loss: 0.0727 - val_acc: 0.9775\n",
      "Epoch 38/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1774 - acc: 0.9459 - val_loss: 0.0725 - val_acc: 0.9773\n",
      "Epoch 39/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1746 - acc: 0.9459 - val_loss: 0.0727 - val_acc: 0.9770\n",
      "Epoch 40/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1748 - acc: 0.9462 - val_loss: 0.0723 - val_acc: 0.9778\n",
      "Epoch 41/100\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1731 - acc: 0.9461 - val_loss: 0.0720 - val_acc: 0.9784\n",
      "Epoch 42/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1745 - acc: 0.9458 - val_loss: 0.0699 - val_acc: 0.9783\n",
      "Epoch 43/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1720 - acc: 0.9463 - val_loss: 0.0697 - val_acc: 0.9783\n",
      "Epoch 44/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1748 - acc: 0.9450 - val_loss: 0.0724 - val_acc: 0.9787\n",
      "Epoch 45/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1707 - acc: 0.9470 - val_loss: 0.0660 - val_acc: 0.9801\n",
      "Epoch 46/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1717 - acc: 0.9468 - val_loss: 0.0691 - val_acc: 0.9778\n",
      "Epoch 47/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1710 - acc: 0.9466 - val_loss: 0.0683 - val_acc: 0.9779\n",
      "Epoch 48/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1695 - acc: 0.9478 - val_loss: 0.0684 - val_acc: 0.9789\n",
      "Epoch 49/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1645 - acc: 0.9481 - val_loss: 0.0754 - val_acc: 0.9753\n",
      "Epoch 50/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1683 - acc: 0.9483 - val_loss: 0.0700 - val_acc: 0.9779\n",
      "Epoch 51/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1687 - acc: 0.9482 - val_loss: 0.0669 - val_acc: 0.9802\n",
      "Epoch 52/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1681 - acc: 0.9481 - val_loss: 0.0707 - val_acc: 0.9780\n",
      "Epoch 53/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1650 - acc: 0.9492 - val_loss: 0.0688 - val_acc: 0.9787\n",
      "Epoch 54/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1641 - acc: 0.9486 - val_loss: 0.0678 - val_acc: 0.9779\n",
      "Epoch 55/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1682 - acc: 0.9485 - val_loss: 0.0661 - val_acc: 0.9793\n",
      "Epoch 56/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1667 - acc: 0.9480 - val_loss: 0.0680 - val_acc: 0.9790\n",
      "Epoch 57/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1638 - acc: 0.9478 - val_loss: 0.0688 - val_acc: 0.9785\n",
      "Epoch 58/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1699 - acc: 0.9473 - val_loss: 0.0669 - val_acc: 0.9786\n",
      "Epoch 59/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1665 - acc: 0.9489 - val_loss: 0.0665 - val_acc: 0.9795\n",
      "Epoch 60/100\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1639 - acc: 0.9489 - val_loss: 0.0658 - val_acc: 0.9785\n",
      "Epoch 61/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1643 - acc: 0.9485 - val_loss: 0.0668 - val_acc: 0.9790\n",
      "Epoch 62/100\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1656 - acc: 0.9488 - val_loss: 0.0644 - val_acc: 0.9798\n",
      "Epoch 63/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1651 - acc: 0.9493 - val_loss: 0.0654 - val_acc: 0.9783\n",
      "Epoch 64/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1633 - acc: 0.9500 - val_loss: 0.0683 - val_acc: 0.9786\n",
      "Epoch 65/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1642 - acc: 0.9492 - val_loss: 0.0665 - val_acc: 0.9780\n",
      "Epoch 66/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1624 - acc: 0.9496 - val_loss: 0.0658 - val_acc: 0.9781\n",
      "Epoch 67/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1607 - acc: 0.9499 - val_loss: 0.0651 - val_acc: 0.9805\n",
      "Epoch 68/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1592 - acc: 0.9503 - val_loss: 0.0637 - val_acc: 0.9799\n",
      "Epoch 69/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1628 - acc: 0.9500 - val_loss: 0.0667 - val_acc: 0.9791\n",
      "Epoch 70/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1614 - acc: 0.9498 - val_loss: 0.0672 - val_acc: 0.9791\n",
      "Epoch 71/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1609 - acc: 0.9501 - val_loss: 0.0631 - val_acc: 0.9807\n",
      "Epoch 72/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1655 - acc: 0.9490 - val_loss: 0.0638 - val_acc: 0.9793\n",
      "Epoch 73/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1619 - acc: 0.9501 - val_loss: 0.0663 - val_acc: 0.9780\n",
      "Epoch 74/100\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1623 - acc: 0.9489 - val_loss: 0.0686 - val_acc: 0.9781\n",
      "Epoch 75/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1592 - acc: 0.9507 - val_loss: 0.0668 - val_acc: 0.9791\n",
      "Epoch 76/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1620 - acc: 0.9500 - val_loss: 0.0655 - val_acc: 0.9793\n",
      "Epoch 77/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1599 - acc: 0.9501 - val_loss: 0.0647 - val_acc: 0.9793\n",
      "Epoch 78/100\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1624 - acc: 0.9500 - val_loss: 0.0663 - val_acc: 0.9777\n",
      "Epoch 79/100\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1613 - acc: 0.9498 - val_loss: 0.0645 - val_acc: 0.9782\n",
      "Epoch 80/100\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1601 - acc: 0.9498 - val_loss: 0.0639 - val_acc: 0.9792\n",
      "Epoch 81/100\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.1596 - acc: 0.9504 - val_loss: 0.0676 - val_acc: 0.9784\n",
      "Epoch 82/100\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.1625 - acc: 0.9499 - val_loss: 0.0639 - val_acc: 0.9792\n",
      "Epoch 83/100\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.1638 - acc: 0.9495 - val_loss: 0.0674 - val_acc: 0.9778\n",
      "Epoch 84/100\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1593 - acc: 0.9494 - val_loss: 0.0670 - val_acc: 0.9794\n",
      "Epoch 85/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1624 - acc: 0.9491 - val_loss: 0.0651 - val_acc: 0.9784\n",
      "Epoch 86/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1637 - acc: 0.9500 - val_loss: 0.0631 - val_acc: 0.9794\n",
      "Epoch 87/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1623 - acc: 0.9496 - val_loss: 0.0698 - val_acc: 0.9776\n",
      "Epoch 88/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1646 - acc: 0.9501 - val_loss: 0.0653 - val_acc: 0.9795\n",
      "Epoch 89/100\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1568 - acc: 0.9513 - val_loss: 0.0644 - val_acc: 0.9795\n",
      "Epoch 90/100\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1603 - acc: 0.9500 - val_loss: 0.0624 - val_acc: 0.9809\n",
      "Epoch 91/100\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.1612 - acc: 0.9514 - val_loss: 0.0685 - val_acc: 0.9775\n",
      "Epoch 92/100\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1644 - acc: 0.9488 - val_loss: 0.0688 - val_acc: 0.9777\n",
      "Epoch 93/100\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1603 - acc: 0.9493 - val_loss: 0.0741 - val_acc: 0.9769\n",
      "Epoch 94/100\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1594 - acc: 0.9505 - val_loss: 0.0666 - val_acc: 0.9782\n",
      "Epoch 95/100\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1605 - acc: 0.9515 - val_loss: 0.0648 - val_acc: 0.9797\n",
      "Epoch 96/100\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1561 - acc: 0.9516 - val_loss: 0.0655 - val_acc: 0.9790\n",
      "Epoch 97/100\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1583 - acc: 0.9507 - val_loss: 0.0648 - val_acc: 0.9795\n",
      "Epoch 98/100\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1596 - acc: 0.9510 - val_loss: 0.0717 - val_acc: 0.9781\n",
      "Epoch 99/100\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1601 - acc: 0.9511 - val_loss: 0.0673 - val_acc: 0.9784\n",
      "Epoch 100/100\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.1597 - acc: 0.9505 - val_loss: 0.0659 - val_acc: 0.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15f3a40d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.fit(X_train, y_train, epochs=100, batch_size=128, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 4)         40        \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 26, 26, 4)         0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 4)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 8)         296       \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 11, 11, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 200)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,346\n",
      "Trainable params: 2,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(full_model.input, full_model.layers[-2].output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(X_train).batch(1).take(100):\n",
    "    # Model has only one input so each data point has one element.\n",
    "    yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/gt/sg3v8rd13l52jx91mfbgzbfc0000gn/T/tmpu47z18n5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/gt/sg3v8rd13l52jx91mfbgzbfc0000gn/T/tmpu47z18n5/assets\n",
      "/Users/sty/miniforge3/envs/tf-cpu/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2022-12-11 01:20:45.994077: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-12-11 01:20:45.994091: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-12-11 01:20:45.994249: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/gt/sg3v8rd13l52jx91mfbgzbfc0000gn/T/tmpu47z18n5\n",
      "2022-12-11 01:20:45.995189: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-12-11 01:20:45.995195: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/gt/sg3v8rd13l52jx91mfbgzbfc0000gn/T/tmpu47z18n5\n",
      "2022-12-11 01:20:45.997371: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2022-12-11 01:20:45.997959: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-12-11 01:20:46.010122: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/gt/sg3v8rd13l52jx91mfbgzbfc0000gn/T/tmpu47z18n5\n",
      "2022-12-11 01:20:46.015220: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 20975 microseconds.\n",
      "2022-12-11 01:20:46.025710: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "INFO: Initialized TensorFlow Lite runtime.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# converter.inference_input_type = tf.int8\n",
    "# converter.inference_output_type = tf.int8\n",
    "converter._experimental_disable_per_channel = True\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5944"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"./\")\n",
    "# tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the quantized model:\n",
    "tflite_model_quant_file = tflite_models_dir/\"mnist_convnet_quant.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run inference on a TFLite model\n",
    "def run_tflite_model(tflite_file, test_image_indices):\n",
    "  global X_test\n",
    "\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "  for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = X_test[test_image_index]\n",
    "    test_label = y_test[test_image_index]\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function to test the models on one image\n",
    "def test_model(tflite_file, test_image_index, model_type):\n",
    "  global y_test\n",
    "\n",
    "  predictions = run_tflite_model(tflite_file, [test_image_index])\n",
    "\n",
    "  plt.imshow(X_test[test_image_index])\n",
    "  template = model_type + \" Model \\n True:{true}, Predicted:{predict}\"\n",
    "  _ = plt.title(template.format(true= str(y_test[test_image_index].argmax()), predict=str(predictions[0])))\n",
    "  plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Initialized TensorFlow Lite runtime.\n",
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change this to test a different image\n",
    "test_image_index = 400\n",
    "test_model(tflite_model_quant_file, test_image_index, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to evaluate a TFLite model on all images\n",
    "def evaluate_model(tflite_file, model_type):\n",
    "  global X_test\n",
    "  global y_test\n",
    "\n",
    "  test_image_indices = range(X_test.shape[0])\n",
    "  predictions = run_tflite_model(tflite_file, test_image_indices)\n",
    "\n",
    "  accuracy = (np.sum(np.argmax(y_test, axis=1)== predictions) * 100) / len(X_test)\n",
    "\n",
    "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
    "      model_type, accuracy, len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model accuracy is 97.9500% (Number of test samples=10000)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(tflite_model_quant_file, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_1',\n",
       " 'conv2d',\n",
       " 're_lu',\n",
       " 'max_pooling2d',\n",
       " 'conv2d_1',\n",
       " 're_lu_1',\n",
       " 'max_pooling2d_1',\n",
       " 'flatten',\n",
       " 'dropout',\n",
       " 'dense']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l.name for l in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_json = {}\n",
    "scale = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input details ==\n",
      "name: serving_default_input_1:0\n",
      "shape: [ 1 28 28  1]\n",
      "type: <class 'numpy.float32'>\n",
      "\n",
      "== Output details ==\n",
      "name: StatefulPartitionedCall:0\n",
      "shape: [ 1 10]\n",
      "type: <class 'numpy.float32'>\n",
      "dense_bias (10,) [ 1882  7290 -3220 -3212 -2238 -5057   964 -6501  6977   323] 0.00040966662345454097\n",
      "dense_weights (200, 10) 0.013641951605677605\n",
      "conv2d_1_bias (8,) [ -87  265   -2 -179   -5 -356   -3  -14] 0.0008817124180495739\n",
      "conv2d_1_weights (3, 3, 4, 8) 0.007074496243149042\n",
      "conv2d_bias (4,) [-359   -2   -1    2] 0.0019289110787212849\n",
      "conv2d_weights (3, 3, 1, 4) 0.0019289110787212849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create interpreter, allocate tensors\n",
    "'''\n",
    "tflite_interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "tflite_interpreter.allocate_tensors()\n",
    "\n",
    "'''\n",
    "Check input/output details\n",
    "'''\n",
    "input_details = tflite_interpreter.get_input_details()\n",
    "output_details = tflite_interpreter.get_output_details()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", input_details[0]['name'])\n",
    "print(\"shape:\", input_details[0]['shape'])\n",
    "print(\"type:\", input_details[0]['dtype'])\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\", output_details[0]['name'])\n",
    "print(\"shape:\", output_details[0]['shape'])\n",
    "print(\"type:\", output_details[0]['dtype'])\n",
    "\n",
    "'''\n",
    "This gives a list of dictionaries. \n",
    "'''\n",
    "tensor_details = tflite_interpreter.get_tensor_details()\n",
    "\n",
    "for dict in tensor_details:\n",
    "    i = dict['index']\n",
    "    tensor_name = dict['name']\n",
    "    scales = dict['quantization'][0]\n",
    "    zero_points = dict['quantization'][1]\n",
    "    tensor = tflite_interpreter.tensor(i)()\n",
    "\n",
    "    # print(i, type, tensor_name, scales, zero_points)\n",
    "    # print(dict)\n",
    "    if \"model_1/conv2d/Conv2D\" == tensor_name:\n",
    "        weights = tensor\n",
    "        weights = np.rollaxis(weights, 0,4)\n",
    "        in_json['conv2d_weights'] = weights\n",
    "        scale['conv2d_weights'] = scales\n",
    "        print('conv2d_weights', weights.shape, scales)\n",
    "    elif \"model_1/conv2d/BiasAdd/ReadVariableOp\" == tensor_name:\n",
    "        biases = tensor\n",
    "        in_json['conv2d_bias'] = biases.flatten().tolist()\n",
    "        scale['conv2d_bias'] = scales\n",
    "        print('conv2d_bias', biases.shape, biases, scales)\n",
    "    elif \"model_1/conv2d_1/Conv2D\" == tensor_name:\n",
    "        weights = tensor\n",
    "        weights = np.rollaxis(weights, 0,4)\n",
    "        in_json['conv2d_1_weights'] = weights\n",
    "        scale['conv2d_1_weights'] = scales\n",
    "        print('conv2d_1_weights', weights.shape, scales)\n",
    "    elif \"model_1/conv2d_1/BiasAdd/ReadVariableOp\" == tensor_name:\n",
    "        biases = tensor\n",
    "        in_json['conv2d_1_bias'] = biases.flatten().tolist()\n",
    "        scale['conv2d_1_bias'] = scales\n",
    "        print('conv2d_1_bias', biases.shape, biases, scales)\n",
    "    elif \"model_1/dense/MatMul\" == tensor_name:\n",
    "        weights = tensor\n",
    "        weights = np.rollaxis(weights, 1)\n",
    "        in_json['dense_weights'] = weights\n",
    "        scale['dense_weights'] = scales\n",
    "        print('dense_weights', weights.shape, scales)\n",
    "    elif \"model_1/dense/BiasAdd/ReadVariableOp\" == tensor_name:\n",
    "        biases = tensor\n",
    "        in_json['dense_bias'] = biases.flatten().tolist()\n",
    "        scale['dense_bias'] = scales\n",
    "        print('dense_bias', biases.shape, biases, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dense_bias', 'dense_weights', 'conv2d_1_bias', 'conv2d_1_weights', 'conv2d_bias', 'conv2d_weights'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_json.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dense_bias': 0.00040966662345454097,\n",
       " 'dense_weights': 0.013641951605677605,\n",
       " 'conv2d_1_bias': 0.0008817124180495739,\n",
       " 'conv2d_1_weights': 0.007074496243149042,\n",
       " 'conv2d_bias': 0.0019289110787212849,\n",
       " 'conv2d_weights': 0.0019289110787212849}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1.   -2. -127.    7.   10.   -2.  -33.    2.   22.  -11.    6.    9.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, -2, -127, 7, 10, -2, -33, 2, 22, -11, 6, 9]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_json['conv2d_weights'] = in_json['conv2d_weights']*(scale['conv2d_weights']/scale['conv2d_bias'])\n",
    "print(in_json['conv2d_weights'][0].flatten())\n",
    "in_json['conv2d_weights'] = in_json['conv2d_weights'].round().astype(int).flatten().tolist()\n",
    "in_json['conv2d_weights'][:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -8.02358694  -8.02358694  24.07076082 -48.14152165 -24.07076082\n",
      " 160.47173882  16.04717388  40.1179347 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-8, -8, 24, -48, -24, 160, 16, 40]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_json['conv2d_1_weights'] = in_json['conv2d_1_weights']*(scale['conv2d_1_weights']/scale['conv2d_1_bias'])\n",
    "print(in_json['conv2d_1_weights'][0][0][0].flatten())\n",
    "in_json['conv2d_1_weights'] = in_json['conv2d_1_weights'].round().astype(int).flatten().tolist()\n",
    "in_json['conv2d_1_weights'][:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -266.40103586  -133.20051793   632.70246017   366.30142431\n",
      "  -566.1022012  -1431.90556775   266.40103586   266.40103586\n",
      " -1565.10608568 -3429.91333669]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-266, -133, 633, 366, -566, -1432, 266, 266, -1565, -3430]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_json['dense_weights'] = in_json['dense_weights']*(scale['dense_weights']/scale['dense_bias'])\n",
    "print(in_json['dense_weights'][0].flatten())\n",
    "in_json['dense_weights'] = in_json['dense_weights'].round().astype(int).flatten().tolist()\n",
    "in_json['dense_weights'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17b9becd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = X_test[[0]]\n",
    "plt.imshow(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -2.8180332 ,  -7.8118086 ,   3.4019184 ,   0.27658188,\n",
       "        -14.287446  , -11.729616  , -29.31386   ,  12.413387  ,\n",
       "         -5.9041095 ,  -2.54478   ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predict(X)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_json[\"in\"] = X.astype(int).flatten().tolist(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scale': 6.967384006397277e-10,\n",
       " 'out': [-2.818033218383789,\n",
       "  -7.8118085861206055,\n",
       "  3.401918411254883,\n",
       "  0.27658188343048096,\n",
       "  -14.287446022033691,\n",
       "  -11.729616165161133,\n",
       "  -29.313859939575195,\n",
       "  12.413387298583984,\n",
       "  -5.904109477996826,\n",
       "  -2.5447800159454346],\n",
       " 'label': 7}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_json = {\n",
    "    \"scale\": scale['conv2d_bias']*scale['conv2d_1_bias']*scale['dense_bias'],\n",
    "    \"out\": y.flatten().tolist(),\n",
    "    \"label\": int(y_test[0].argmax())\n",
    "}\n",
    "out_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mnist_convnet_input.json\", \"w\") as f:\n",
    "    json.dump(in_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mnist_convnet_output.json\", \"w\") as f:\n",
    "    json.dump(out_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04827827630835111"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv2d_weights mape\n",
    "(np.abs((model.weights[0].numpy().flatten()-np.array(in_json['conv2d_weights'])*scale['conv2d_bias'])/model.weights[0].numpy().flatten())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3162336868466024"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv2d_bias mape\n",
    "(np.abs((model.weights[1].numpy().flatten()-np.array(in_json['conv2d_bias'])*scale['conv2d_bias'])/model.weights[1].numpy().flatten())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07922936952167237"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv2d_1_weights mape\n",
    "(np.abs((model.weights[2].numpy().flatten()-np.array(in_json['conv2d_1_weights'])*scale['conv2d_1_bias'])/model.weights[2].numpy().flatten())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0320445054168509"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv2d_1_bias mape\n",
    "(np.abs((model.weights[3].numpy().flatten()-np.array(in_json['conv2d_1_bias'])*scale['conv2d_1_bias'])/model.weights[3].numpy().flatten())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09156827584568371"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dense_weights mape\n",
    "(np.abs((model.weights[4].numpy().flatten()-np.array(in_json['dense_weights'])*scale['dense_bias'])/model.weights[4].numpy().flatten())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00021858932254896152"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dense_bias mape\n",
    "(np.abs((model.weights[5].numpy().flatten()-np.array(in_json['dense_bias'])*scale['dense_bias'])/model.weights[5].numpy().flatten())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf-cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9449095698c6ddbfb01f56d5f26ea4d918be7e2252dcbff228035a3e4c87e117"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
